{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.prompts import load_prompt, ChatPromptTemplate\n",
    "from langchain.schema import AIMessage, HumanMessage, BaseMessage\n",
    "\n",
    "from langchain_core.callbacks import BaseCallbackHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"http://localhost:8000\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_messages(messages):\n",
    "    unpacked = \"\"\n",
    "    for message in messages:\n",
    "        if isinstance(message, HumanMessage):\n",
    "            unpacked += f\"User: {message.content}\\n\"\n",
    "        elif isinstance(message, AIMessage):\n",
    "            unpacked += f\"AI: {message.content}\\n\"\n",
    "        # Add more conditions here if you're using other message types\n",
    "    return unpacked\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = ChatOpenAI(model_name = \"gpt-3.5-turbo\", temperature=1.2, model_kwargs={\"top_p\": 0.5})\n",
    "# llm = ChatOpenAI(model_name = \"gpt-4\", temperature=1.2, model_kwargs={\"top_p\": 0.5})\n",
    "llm = ChatOpenAI(model_name = \"gpt-4\", temperature=1.2)\n",
    "\n",
    "SYSTEM_THOUGHT = load_prompt('prompts/thought.yaml')\n",
    "SYSTEM_RESPONSE = load_prompt('prompts/response.yaml')\n",
    "SYSTEM_USER_PREDICTION_THOUGHT = load_prompt('prompts/user_prediction_thought.yaml')\n",
    "\n",
    "system_thought = SystemMessagePromptTemplate(prompt=SYSTEM_THOUGHT)\n",
    "system_response = SystemMessagePromptTemplate(prompt=SYSTEM_RESPONSE)\n",
    "system_user_prediction_thought = SystemMessagePromptTemplate(prompt=SYSTEM_USER_PREDICTION_THOUGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = {\n",
    "\t\"thoughts\": [],\n",
    "\t\"responses\": [],\n",
    "\t\"user_prediction_thought\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderings:\n",
    "- Why does the `think` step only consider the previous `thoughts` and not `responses`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def think(query: str):\n",
    "\t\"\"\"Generate Bloom's thought on the user.\"\"\"\n",
    "\n",
    "\tthought_prompt = ChatPromptTemplate.from_messages([\n",
    "\t\tsystem_thought,\n",
    "\t\t*messages[\"thoughts\"],\n",
    "\t\tHumanMessage(content=query)\n",
    "\t])\n",
    "\n",
    "\tchain = thought_prompt | llm \n",
    "\n",
    "\n",
    "\tclass SaveMessagesHandler(BaseCallbackHandler):\n",
    "\t\tdef on_llm_end(self, response, **kwargs):\n",
    "\t\t\tai_response = response.generations[0][0].text\n",
    "\n",
    "\t\t\tmessages[\"thoughts\"].append(HumanMessage(content=query))\n",
    "\t\t\tmessages[\"thoughts\"].append(AIMessage(content=ai_response))\n",
    "\n",
    "\tsave_messages_handler = SaveMessagesHandler()\n",
    "\n",
    "\treturn chain.invoke({}, config={\n",
    "\t\t\"callbacks\": [save_messages_handler]\n",
    "\t})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def respond(thought: str, query: str):\n",
    "\t\"\"\"Generate Bloom's response to the user.\"\"\"\n",
    "\n",
    "\tresponse_prompt = ChatPromptTemplate.from_messages([\n",
    "\t\tsystem_response,\n",
    "\t\t*messages[\"responses\"],\n",
    "\t\tHumanMessage(content=query)\n",
    "\t])\n",
    "\n",
    "\tchain = response_prompt | llm \n",
    "\n",
    "\n",
    "\tclass SaveMessagesHandler(BaseCallbackHandler):\n",
    "\t\tdef on_llm_end(self, response, **kwargs):\n",
    "\t\t\tai_response = response.generations[0][0].text\n",
    "\n",
    "\t\t\tmessages[\"responses\"].append(HumanMessage(content=query))\n",
    "\t\t\tmessages[\"responses\"].append(AIMessage(content=ai_response))\n",
    "\n",
    "\tsave_messages_handler = SaveMessagesHandler()\n",
    "\n",
    "\treturn chain.invoke({\"thought\": thought}, config={\n",
    "\t\t\"callbacks\": [save_messages_handler]\n",
    "\t})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wonderings:\n",
    "- Where is `user_prediction_thought` used??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def think_user_prediction():\n",
    "\t\"\"\"Generate a thought about what the user is going to say\"\"\"\n",
    "\n",
    "\tprompt = ChatPromptTemplate.from_messages([\n",
    "\t\tsystem_user_prediction_thought,\n",
    "\t])\n",
    "\n",
    "\tchain = prompt | llm\n",
    "\n",
    "\thistory = unpack_messages(messages[\"responses\"])\n",
    "\n",
    "\tuser_prediction_thought = chain.invoke({\"history\": history})\n",
    "\n",
    "\tmessages[\"user_prediction_thought\"].append(user_prediction_thought)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query: str ) -> tuple[str, str]:\n",
    "\tthought = think(query=query)\n",
    "\n",
    "\tresponse = respond(thought=thought, query=query)\n",
    "\n",
    "\tthink_user_prediction()\n",
    "\n",
    "\treturn thought, response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AIMessage(content='User appears confused with distinguishing philosophical and educational concepts, like constructivism and constructionism. Predicted need: References or resources with clear explanations to explain the distinction and possibly similar foundational theories that surround these concepts.\\n\\nAdditional helpful data for future predictions: user’s academic background, previous exposure to or experience with pedagogic concepts, and understanding of educational principles. This will provide contextual backgrounds to tailor the explanations.', response_metadata={'token_usage': {'completion_tokens': 80, 'prompt_tokens': 84, 'total_tokens': 164}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}),\n",
       " AIMessage(content=\"Constructionism and constructivism are indeed quite similar because they're both educational theories about how people learn, but they focus on slightly different aspects. \\n\\nConstructivism is about how individuals create their own understanding and knowledge through experiences. According to constructivist theorists such as Jean Piaget, learning takes place when a learner engages with a concept or problem and, through that interaction, creates new knowledge. The emphasis here is on the individual's internal mental construction of knowledge.\\n\\nOn the other hand, the theory of constructionism extends on the ideas of constructivism to specify that this construction of knowledge happens most effectively when people are creating a meaningful product. That's why constructionism often involves hands-on kinds of activities. Termed by Seymour Papert, he situated this theory concretely around the learner's experience within social contexts (such as building, examining, or deliberating a shared project). \\n\\nUltimately, both theories are interlinked; they improve our understanding of the robust cognitive process involved in learning. But they differ slightly in their areas of focus – individual mental process in constructivism, and creating tangible things in a shared context in constructionism.\\n\\nSo, talking specifically about your experiences, have you been involved in any educational setting where these concepts seem to be at work?\", response_metadata={'token_usage': {'completion_tokens': 251, 'prompt_tokens': 292, 'total_tokens': 543}, 'model_name': 'gpt-4', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"I'm not able to understand the difference between constructionism and constructivism\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "course-lm-backend-OOVGKqfC-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
